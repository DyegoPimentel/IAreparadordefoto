{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto Integrador 4b.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5VIahhm6OkGY",
        "wVWFbLdxQuV_",
        "ZRCDTK6NSX2M",
        "4-3AQhlLaer3",
        "MMda0WBe0gpJ",
        "4dTS0GOQ4yXf",
        "fGHc3tkNL4oU"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a8435a253254079b0fa12dc2e023fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ea6e34320d040aeb87d52712448adf8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_07463e1fa3a3498aa2401d8339fca84a",
              "IPY_MODEL_5a6998e3a1a043ce98a7f5f7c9c3ee6e"
            ]
          }
        },
        "5ea6e34320d040aeb87d52712448adf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07463e1fa3a3498aa2401d8339fca84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8a332a9372c04602812fd3b3eab6d208",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 178793939,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 178793939,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c62d8baea1ff4680906e83e419d32c02"
          }
        },
        "5a6998e3a1a043ce98a7f5f7c9c3ee6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bffbe7b301c44c25985893ab87856897",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 171M/171M [00:03&lt;00:00, 49.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da82995843554b7bbd8fb51b1ccaa45d"
          }
        },
        "8a332a9372c04602812fd3b3eab6d208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c62d8baea1ff4680906e83e419d32c02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bffbe7b301c44c25985893ab87856897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da82995843554b7bbd8fb51b1ccaa45d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DyegoPimentel/IAreparadordefoto/blob/main/Reparador%20de%20Fotos%20com%20IA%20e%20CUDA%20-%20Projeto_Integrador_4b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONMJ9z7AK1tL"
      },
      "source": [
        "# **Projeto Integrador IV-B**\n",
        "\n",
        "**Integrantes:**\n",
        "\n",
        "Angelus Victor Saraiva Borges<br>\n",
        "Diego de Medeiros<br>\n",
        "Dyego Lourenço Pimentel<br>\n",
        "Vanessa Pereira Leite<br>\n",
        "Ysaque Araujo Martins\n",
        "\n",
        "**Resumo:** Neste projeto integrador, realizamos a junção de dois algoritimos de processamento paralelo que, primeiro restaura fotos antigas rasgadas, e depois colore as mesmas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZavvJoVMlLk"
      },
      "source": [
        "# ◢ **<font color='#FF000'> IMPORTANTE </font>**\n",
        "\n",
        "Em \"Ambiente de execução/Runtime\" do seu notebook, certifique-se de alterar o tipo de ambiente da seguinte forma: \n",
        "* Runtime Type = Python 3\n",
        "* Hardware Accelerator = GPU \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VIahhm6OkGY"
      },
      "source": [
        "#◢ Git clone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYsmQAu6Ox1f"
      },
      "source": [
        "No codigo abaixo, clonamos do github da microsoft o algoritmo \"Bringin old photos back to life\". Este algoritmo é responsável por realizar a restauração de fotos antigas e/ou rasgadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3khjWt3oKZcm",
        "outputId": "371eb957-65fc-4d99-c368-6d6f60fd2089"
      },
      "source": [
        "!git clone https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life.git photo_restoration"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'photo_restoration'...\n",
            "remote: Enumerating objects: 400, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 400 (delta 39), reused 64 (delta 34), pack-reused 314\u001b[K\n",
            "Receiving objects: 100% (400/400), 17.70 MiB | 11.49 MiB/s, done.\n",
            "Resolving deltas: 100% (155/155), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhK87XngP3ur"
      },
      "source": [
        "No código abaixo, clonamos do github da jantic o algoritmo \"DeOldify\". Este algoritmo é responsável por realizar a colorização de fotos preto e branco, ou em sepia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDcPyXo5K60h",
        "outputId": "9a1054d9-64b7-4943-f8a7-36a63d833304"
      },
      "source": [
        "!git clone https://github.com/jantic/DeOldify.git DeOldify "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeOldify'...\n",
            "remote: Enumerating objects: 2260, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 2260 (delta 13), reused 15 (delta 4), pack-reused 2228\u001b[K\n",
            "Receiving objects: 100% (2260/2260), 69.42 MiB | 22.67 MiB/s, done.\n",
            "Resolving deltas: 100% (1020/1020), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVWFbLdxQuV_"
      },
      "source": [
        "#◢ Configurando o Ambiênte | Bringin old photos back to life."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP8DysLLRAnh"
      },
      "source": [
        "No código abaixo, configuramos o ambiente para que o algoritmo \"Bringin old photos back to life\" funcione corretamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3prvZ6lOodV",
        "outputId": "b41d51e2-cbc5-437c-f649-44ed8138096f"
      },
      "source": [
        "# pull the syncBN repo\n",
        "%cd photo_restoration/Face_Enhancement/models/networks\n",
        "!git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "!cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "%cd ../../../\n",
        "\n",
        "%cd Global/detection_models\n",
        "!git clone https://github.com/vacancy/Synchronized-BatchNorm-PyTorch\n",
        "!cp -rf Synchronized-BatchNorm-PyTorch/sync_batchnorm .\n",
        "%cd ../../\n",
        "\n",
        "# download the landmark detection model\n",
        "%cd Face_Detection/\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d shape_predictor_68_face_landmarks.dat.bz2\n",
        "%cd ../\n",
        "\n",
        "# download the pretrained model\n",
        "%cd Face_Enhancement/\n",
        "!wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Face_Enhancement/checkpoints.zip\n",
        "!unzip checkpoints.zip\n",
        "%cd ../\n",
        "\n",
        "%cd Global/\n",
        "!wget https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Global/checkpoints.zip\n",
        "!unzip checkpoints.zip\n",
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/photo_restoration/Face_Enhancement/models/networks\n",
            "Cloning into 'Synchronized-BatchNorm-PyTorch'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 188 (delta 10), reused 27 (delta 10), pack-reused 161\u001b[K\n",
            "Receiving objects: 100% (188/188), 47.20 KiB | 644.00 KiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n",
            "/content/photo_restoration\n",
            "/content/photo_restoration/Global/detection_models\n",
            "Cloning into 'Synchronized-BatchNorm-PyTorch'...\n",
            "remote: Enumerating objects: 188, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 188 (delta 10), reused 27 (delta 10), pack-reused 161\u001b[K\n",
            "Receiving objects: 100% (188/188), 47.20 KiB | 6.74 MiB/s, done.\n",
            "Resolving deltas: 100% (106/106), done.\n",
            "/content/photo_restoration\n",
            "/content/photo_restoration/Face_Detection\n",
            "--2021-06-21 21:55:08--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  61.07M  26.2MB/s    in 2.3s    \n",
            "\n",
            "2021-06-21 21:55:11 (26.2 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n",
            "/content/photo_restoration\n",
            "/content/photo_restoration/Face_Enhancement\n",
            "--2021-06-21 21:55:18--  https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Face_Enhancement/checkpoints.zip\n",
            "Resolving facevc.blob.core.windows.net (facevc.blob.core.windows.net)... 20.60.68.132\n",
            "Connecting to facevc.blob.core.windows.net (facevc.blob.core.windows.net)|20.60.68.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 342496657 (327M) [application/x-zip-compressed]\n",
            "Saving to: ‘checkpoints.zip’\n",
            "\n",
            "checkpoints.zip     100%[===================>] 326.63M  14.2MB/s    in 25s     \n",
            "\n",
            "2021-06-21 21:55:43 (13.1 MB/s) - ‘checkpoints.zip’ saved [342496657/342496657]\n",
            "\n",
            "Archive:  checkpoints.zip\n",
            "   creating: checkpoints/\n",
            "   creating: checkpoints/Setting_9_epoch_100/\n",
            "  inflating: checkpoints/Setting_9_epoch_100/latest_net_G.pth  \n",
            "/content/photo_restoration\n",
            "/content/photo_restoration/Global\n",
            "--2021-06-21 21:55:48--  https://facevc.blob.core.windows.net/zhanbo/old_photo/pretrain/Global/checkpoints.zip\n",
            "Resolving facevc.blob.core.windows.net (facevc.blob.core.windows.net)... 20.60.68.132\n",
            "Connecting to facevc.blob.core.windows.net (facevc.blob.core.windows.net)|20.60.68.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1739076350 (1.6G) [application/x-zip-compressed]\n",
            "Saving to: ‘checkpoints.zip’\n",
            "\n",
            "checkpoints.zip     100%[===================>]   1.62G  14.1MB/s    in 2m 4s   \n",
            "\n",
            "2021-06-21 21:57:52 (13.4 MB/s) - ‘checkpoints.zip’ saved [1739076350/1739076350]\n",
            "\n",
            "Archive:  checkpoints.zip\n",
            "   creating: checkpoints/\n",
            "   creating: checkpoints/detection/\n",
            "  inflating: checkpoints/detection/FT_Epoch_latest.pt  \n",
            "   creating: checkpoints/restoration/\n",
            "   creating: checkpoints/restoration/mapping_quality/\n",
            "  inflating: checkpoints/restoration/mapping_quality/latest_net_D.pth  \n",
            "  inflating: checkpoints/restoration/mapping_quality/latest_net_mapping_net.pth  \n",
            "  inflating: checkpoints/restoration/mapping_quality/latest_optimizer_D.pth  \n",
            "  inflating: checkpoints/restoration/mapping_quality/latest_optimizer_mapping_net.pth  \n",
            "   creating: checkpoints/restoration/mapping_scratch/\n",
            " extracting: checkpoints/restoration/mapping_scratch/iter.txt  \n",
            "  inflating: checkpoints/restoration/mapping_scratch/latest_net_D.pth  \n",
            "  inflating: checkpoints/restoration/mapping_scratch/latest_net_mapping_net.pth  \n",
            "  inflating: checkpoints/restoration/mapping_scratch/latest_optimizer_D.pth  \n",
            "  inflating: checkpoints/restoration/mapping_scratch/latest_optimizer_mapping_net.pth  \n",
            "  inflating: checkpoints/restoration/mapping_scratch/loss_log.txt  \n",
            "  inflating: checkpoints/restoration/mapping_scratch/model.txt  \n",
            "   creating: checkpoints/restoration/VAE_A_quality/\n",
            "  inflating: checkpoints/restoration/VAE_A_quality/latest_net_D.pth  \n",
            "  inflating: checkpoints/restoration/VAE_A_quality/latest_net_featD.pth  \n",
            "  inflating: checkpoints/restoration/VAE_A_quality/latest_net_G.pth  \n",
            "  inflating: checkpoints/restoration/VAE_A_quality/latest_optimizer_D.pth  \n",
            "  inflating: checkpoints/restoration/VAE_A_quality/latest_optimizer_featD.pth  \n",
            "  inflating: checkpoints/restoration/VAE_A_quality/latest_optimizer_G.pth  \n",
            "   creating: checkpoints/restoration/VAE_B_quality/\n",
            "  inflating: checkpoints/restoration/VAE_B_quality/latest_net_D.pth  \n",
            "  inflating: checkpoints/restoration/VAE_B_quality/latest_net_G.pth  \n",
            "  inflating: checkpoints/restoration/VAE_B_quality/latest_optimizer_D.pth  \n",
            "  inflating: checkpoints/restoration/VAE_B_quality/latest_optimizer_G.pth  \n",
            "   creating: checkpoints/restoration/VAE_B_scratch/\n",
            "  inflating: checkpoints/restoration/VAE_B_scratch/latest_net_D.pth  \n",
            "  inflating: checkpoints/restoration/VAE_B_scratch/latest_net_G.pth  \n",
            "  inflating: checkpoints/restoration/VAE_B_scratch/latest_optimizer_D.pth  \n",
            "  inflating: checkpoints/restoration/VAE_B_scratch/latest_optimizer_G.pth  \n",
            "/content/photo_restoration\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap7ltJXbRf-z"
      },
      "source": [
        "No código abaixo, instalamos todas as bibliotecas necessárias para que o algoritmo \"Bringin old photos back to life\" funcione corretamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpXrDmCURpK1",
        "outputId": "fad24652-77ec-48f6-d7a9-dcb740ccf569"
      },
      "source": [
        "! pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.10.0+cu102)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (19.18.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.16.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.9)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.13)\n",
            "Collecting dominate>=2.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/a8/4354f8122c39e35516a2708746d89db5e339c867abbd8e0179bccee4b7f9/dominate-2.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.3.4)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 19.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (4.1.2.30)\n",
            "Collecting einops\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Collecting PySimpleGUI\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/05/461ac9ab56511d4ffc3e65c145f4206da96f1a1bb8846994bd1e12eb562f/PySimpleGUI-4.45.0-py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 29.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (2.5.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 4)) (1.1.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 9)) (3.12.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX->-r requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX->-r requirements.txt (line 9)) (57.0.0)\n",
            "Installing collected packages: dominate, tensorboardX, einops, PySimpleGUI\n",
            "Successfully installed PySimpleGUI-4.45.0 dominate-2.6.0 einops-0.3.0 tensorboardX-2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRCDTK6NSX2M"
      },
      "source": [
        "#◢ Configurando o Ambiênte | DeOldify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0aODcDsSaGU"
      },
      "source": [
        "No código abaixo, acessando a pasta DeOldify e realizamos o import do torch, para utilização da GPU CUDA para o processamento paralelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE7NMnO3SZfD",
        "outputId": "1dce5857-4aaa-4c1e-b216-e2c9fa731af0"
      },
      "source": [
        "cd ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSCeA9a0Y6CZ",
        "outputId": "e50095e8-3e40-4543-e673-c8fc7bfe0f8c"
      },
      "source": [
        "cd DeOldify"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeOldify\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00_GcC_trpdE"
      },
      "source": [
        "#NOTE:  This must be the first call in order to work properly!\n",
        "from deoldify import device\n",
        "from deoldify.device_id import DeviceId\n",
        "#choices:  CPU, GPU0...GPU7\n",
        "device.set(device=DeviceId.GPU0)\n",
        "\n",
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print('GPU not available.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glml6gXNTNNB"
      },
      "source": [
        "No código abaixo, realizamos a instalação de todas as bibliotecas necessárias para que o DeOldify funcione corretamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El1TjeMnTWMf",
        "outputId": "9ddb87d7-b88e-4f4e-fcd6-b0a5b321d744"
      },
      "source": [
        "!pip install -r colab_requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai==1.0.51\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/cc/dcc702cf43bb8c908d172e5be156615928f962366a20834c320cbca2b9d0/fastai-1.0.51-py3-none-any.whl (214kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 13.9MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 19.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30kB 23.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 51kB 15.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 61kB 12.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 71kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 81kB 12.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 92kB 13.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 102kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 112kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 122kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 133kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 143kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 153kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 163kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 174kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 184kB 14.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 194kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 204kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 14.3MB/s \n",
            "\u001b[?25hCollecting tensorboardX==1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 25.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 30kB 30.4MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 40kB 32.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 51kB 35.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 61kB 37.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 71kB 37.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 81kB 37.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 92kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 102kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 112kB 24.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 122kB 24.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 24.2MB/s \n",
            "\u001b[?25hCollecting ffmpeg\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/cc/3b7408b8ecf7c1d20ad480c3eaed7619857bf1054b690226e906fdf14258/ffmpeg-1.4.tar.gz\n",
            "Collecting ffmpeg-python==0.1.17\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/10/330cbc8e63d072d40413f4d470444a6a1e8c8c6a80b2a4ac302d1252ca1b/ffmpeg_python-0.1.17-py3-none-any.whl\n",
            "Collecting youtube-dl>=2019.4.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/43/1f586e49e68f8b41c4be416302bf96ddd5040b0e744b5902d51063795eb9/youtube_dl-2021.6.6-py2.py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 25.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3.3.0.10 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: tornado~=5.1.0 in /usr/local/lib/python3.7/dist-packages (from -r colab_requirements.txt (line 8)) (5.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (4.6.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.9.0+cu102)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (20.9)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (3.13)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (0.10.0+cu102)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.7.3)\n",
            "Collecting typing\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/d9/6eebe19d46bd05360c9a9aae822e67a80f9242aabbfc58b641b957546607/typing-3.7.4.3.tar.gz (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (7.352.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.6->-r colab_requirements.txt (line 2)) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.6->-r colab_requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python==0.1.17->-r colab_requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.51->-r colab_requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.51->-r colab_requirements.txt (line 1)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->fastai==1.0.51->-r colab_requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (57.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (3.0.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.51->-r colab_requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.51->-r colab_requirements.txt (line 1)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai==1.0.51->-r colab_requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai==1.0.51->-r colab_requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.51->-r colab_requirements.txt (line 1)) (3.4.1)\n",
            "Building wheels for collected packages: ffmpeg, typing\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-cp37-none-any.whl size=6084 sha256=f48215201f262945a52cb3da1a4670924e58baeeb106d5f6f678b3128039940f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/68/c3/a05a35f647ba871e5572b9bbfc0b95fd1c6637a2219f959e7a\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-cp37-none-any.whl size=26323 sha256=1834f97cfe49b177a53b1ae9b6bfa12ea7e30857ed51d86bc3b8b6e99e68243f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/04/41/8e1836e79581989c22eebac3f4e70aaac9af07b0908da173be\n",
            "Successfully built ffmpeg typing\n",
            "Installing collected packages: typing, fastai, tensorboardX, ffmpeg, ffmpeg-python, youtube-dl\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "  Found existing installation: tensorboardX 2.2\n",
            "    Uninstalling tensorboardX-2.2:\n",
            "      Successfully uninstalled tensorboardX-2.2\n",
            "Successfully installed fastai-1.0.51 ffmpeg-1.4 ffmpeg-python-0.1.17 tensorboardX-1.6 typing-3.7.4.3 youtube-dl-2021.6.6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5lo07rpT3nd"
      },
      "source": [
        "No código abaixo, importamos o fastai e habilitamos o cuda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsJa69CMwj3l"
      },
      "source": [
        "import fastai\n",
        "from deoldify.visualize import *\n",
        "\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJtQs-_RT_OS"
      },
      "source": [
        "No código abaixo, criamos uma pasta para armazenar nosso modelo treinado e realizamos o download do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYc3pKP9TrrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1394453-6e3a-4486-a7ca-8f30c7e6d1e8"
      },
      "source": [
        "!mkdir 'models'\n",
        "!wget https://www.dropbox.com/s/usf7uifrctqw9rl/ColorizeStable_gen.pth?dl=0 -O ./models/ColorizeStable_gen.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-21 21:58:34--  https://www.dropbox.com/s/usf7uifrctqw9rl/ColorizeStable_gen.pth?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.67.18, 2620:100:6020:18::a27d:4012\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.67.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/usf7uifrctqw9rl/ColorizeStable_gen.pth [following]\n",
            "--2021-06-21 21:58:35--  https://www.dropbox.com/s/raw/usf7uifrctqw9rl/ColorizeStable_gen.pth\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uccfe4daed1e2e5484fc224274fb.dl.dropboxusercontent.com/cd/0/inline/BQ1MOTQr0ImgpTPj0QoaSPBGvZOdY2pNMhP7YjUJt0LIbDe6tZDpOWTUseX1_T8Dxzw5iGRKTa9bfHuqTXCs1Bn7GFliuyXrvM1KLnqTLFHd9Faiy8AhfsWr_IgE1FNEfDyghWVJo2qo3oSFG1KYie2a/file# [following]\n",
            "--2021-06-21 21:58:35--  https://uccfe4daed1e2e5484fc224274fb.dl.dropboxusercontent.com/cd/0/inline/BQ1MOTQr0ImgpTPj0QoaSPBGvZOdY2pNMhP7YjUJt0LIbDe6tZDpOWTUseX1_T8Dxzw5iGRKTa9bfHuqTXCs1Bn7GFliuyXrvM1KLnqTLFHd9Faiy8AhfsWr_IgE1FNEfDyghWVJo2qo3oSFG1KYie2a/file\n",
            "Resolving uccfe4daed1e2e5484fc224274fb.dl.dropboxusercontent.com (uccfe4daed1e2e5484fc224274fb.dl.dropboxusercontent.com)... 162.125.64.15, 2620:100:6020:15::a27d:400f\n",
            "Connecting to uccfe4daed1e2e5484fc224274fb.dl.dropboxusercontent.com (uccfe4daed1e2e5484fc224274fb.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BQ1LxoSp70_3OXa9v-bSEos26i6cU2sIxz1_hspI61OObOUhkFN3kyi0UnXTWEM8-sN05PXU7Doth0SOquHro0Id44R4B2PoZAF4KuFlUDkl92rV9evnu-O6MO6qYHGF26XUc5If7mE1we6NtB5HQpXUORtLl5CBJncSHQtI6jVTsjIuz_-x3PZ5KEDz3JIoBY0PJfJwL1RGbPTHCBqtkDDdWJGB27NVL0_W55KbjGBpsI_pXwk0gjjsQQ9UntSeOMp-aHQKFMySPThU1L4GDaaVRTFOsW0wDnKWaGxzrmlUsh1nUwTLRCeN83MMmqXj9fcUDuHFAgkJq0NtjVW-rAqVOGJys3fmhYH84A8Tly3Oko2E4XRSeuKeFM4TBEPu2tw/file [following]\n",
            "--2021-06-21 21:58:36--  https://uccfe4daed1e2e5484fc224274fb.dl.dropboxusercontent.com/cd/0/inline2/BQ1LxoSp70_3OXa9v-bSEos26i6cU2sIxz1_hspI61OObOUhkFN3kyi0UnXTWEM8-sN05PXU7Doth0SOquHro0Id44R4B2PoZAF4KuFlUDkl92rV9evnu-O6MO6qYHGF26XUc5If7mE1we6NtB5HQpXUORtLl5CBJncSHQtI6jVTsjIuz_-x3PZ5KEDz3JIoBY0PJfJwL1RGbPTHCBqtkDDdWJGB27NVL0_W55KbjGBpsI_pXwk0gjjsQQ9UntSeOMp-aHQKFMySPThU1L4GDaaVRTFOsW0wDnKWaGxzrmlUsh1nUwTLRCeN83MMmqXj9fcUDuHFAgkJq0NtjVW-rAqVOGJys3fmhYH84A8Tly3Oko2E4XRSeuKeFM4TBEPu2tw/file\n",
            "Reusing existing connection to uccfe4daed1e2e5484fc224274fb.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 874066230 (834M) [application/octet-stream]\n",
            "Saving to: ‘./models/ColorizeStable_gen.pth’\n",
            "\n",
            "./models/ColorizeSt 100%[===================>] 833.57M  22.4MB/s    in 42s     \n",
            "\n",
            "2021-06-21 21:59:19 (19.7 MB/s) - ‘./models/ColorizeStable_gen.pth’ saved [874066230/874066230]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvNyxvEiUSHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf756ac8-5bb0-4f03-c3cb-f0d08ddde403"
      },
      "source": [
        "!wget https://media.githubusercontent.com/media/jantic/DeOldify/master/resource_images/watermark.png -O ./resource_images/watermark.png"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-21 21:59:19--  https://media.githubusercontent.com/media/jantic/DeOldify/master/resource_images/watermark.png\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9210 (9.0K) [image/png]\n",
            "Saving to: ‘./resource_images/watermark.png’\n",
            "\n",
            "./resource_images/w 100%[===================>]   8.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-21 21:59:19 (55.5 MB/s) - ‘./resource_images/watermark.png’ saved [9210/9210]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQqmYLsfUf83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "8a8435a253254079b0fa12dc2e023fa2",
            "5ea6e34320d040aeb87d52712448adf8",
            "07463e1fa3a3498aa2401d8339fca84a",
            "5a6998e3a1a043ce98a7f5f7c9c3ee6e",
            "8a332a9372c04602812fd3b3eab6d208",
            "c62d8baea1ff4680906e83e419d32c02",
            "bffbe7b301c44c25985893ab87856897",
            "da82995843554b7bbd8fb51b1ccaa45d"
          ]
        },
        "outputId": "b62babad-be09-4805-821d-0342a319e795"
      },
      "source": [
        "colorizer = get_image_colorizer(artistic=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/data_block.py:442: UserWarning: Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\n",
            "  warn(\"Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\")\n",
            "/usr/local/lib/python3.7/dist-packages/fastai/data_block.py:445: UserWarning: Your validation set is empty. If this is by design, use `split_none()`\n",
            "                 or pass `ignore_empty=True` when labelling to remove this warning.\n",
            "  or pass `ignore_empty=True` when labelling to remove this warning.\"\"\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a8435a253254079b0fa12dc2e023fa2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=178793939.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-3AQhlLaer3"
      },
      "source": [
        "#◢ Configurando pastas | input/output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKIPe6zuVgxc"
      },
      "source": [
        "No código abaixo, criamos a pasta imagens. Ela receberá as imagens via upload e também as imagens processadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl4IEpSqanYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac2be56-de6f-4566-bf76-80f4ad755ded"
      },
      "source": [
        "%cd ../\n",
        "\n",
        "!mkdir 'imagens'\n",
        "\n",
        "%cd imagens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/imagens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzEM_ObStV6_"
      },
      "source": [
        "No código abaixo, importamos o OS e criamos algumas variaveis de ambiente. Com isso será possivel realizar o armazenamento das nossas imagens no servidor de arquivos do google colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TErx5hAPjmzM"
      },
      "source": [
        "import io\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "\n",
        "input_folder = \"input_img\"\n",
        "output_folder = \"output_img\"\n",
        "\n",
        "import os\n",
        "basepath = os.getcwd()\n",
        "input_path = os.path.join(basepath, input_folder)\n",
        "output_path = os.path.join(basepath, output_folder)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8XdC72Ldnvs"
      },
      "source": [
        "#◢ Envie sua foto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrljH_1Bt46_"
      },
      "source": [
        "No código abaixo, é possivel enviar sua imagem. Ela será armazenada dentro de \"imagens/input_img\" e será convertida automaticamente para PNG."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMth03Dcd0zL"
      },
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "upload_path = os.path.join(basepath, input_folder)\n",
        "upload_output_path = os.path.join(basepath, output_folder)\n",
        "\n",
        "if os.path.isdir(upload_output_path):\n",
        "    shutil.rmtree(upload_output_path)\n",
        "\n",
        "if os.path.isdir(upload_path):\n",
        "    shutil.rmtree(upload_path)\n",
        "\n",
        "os.mkdir(upload_output_path)\n",
        "os.mkdir(upload_path)\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(os.path.join(basepath, filename), os.path.join(upload_path, filename)+'.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMda0WBe0gpJ"
      },
      "source": [
        "#◢ Restaurar Foto Antiga\n",
        "Nesta seção você consegue, melhorar um pouco da qualidade da sua foto antiga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PQJMHAd091H"
      },
      "source": [
        "No código abaixo, é feito o processamento da imagem original e salva a imagem processada em \"/content/imagens/output_img/final_output\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85tJsRze0h6q"
      },
      "source": [
        "!rm -rf /content/imagens/output_img/\n",
        "\n",
        "%cd /content/photo_restoration/\n",
        "\n",
        "\n",
        "!python run.py --input_folder /content/imagens/input_img/ --output_folder /content/imagens/output_img/ --GPU 0\n",
        "\n",
        "\n",
        "\n",
        "def imshow(a, format='png', jpeg_fallback=True):\n",
        "    a = np.asarray(a, dtype=np.uint8)\n",
        "    data = io.BytesIO()\n",
        "    PIL.Image.fromarray(a).save(data, format)\n",
        "    im_data = data.getvalue()\n",
        "    try:\n",
        "      disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "    except IOError:\n",
        "      if jpeg_fallback and format != 'jpeg':\n",
        "        print(('Warning: image was too large to display in format \"{}\"; '\n",
        "              'trying jpeg instead.').format(format))\n",
        "        return imshow(a, format='jpeg')\n",
        "      else:\n",
        "        raise\n",
        "    return disp\n",
        "\n",
        "def make_grid(I1, I2, resize=True):\n",
        "    I1 = np.asarray(I1)\n",
        "    H, W = I1.shape[0], I1.shape[1]\n",
        "    \n",
        "    if I1.ndim >= 3:\n",
        "        I2 = np.asarray(I2.resize((W,H)))\n",
        "        I_combine = np.zeros((H,W*2,3))\n",
        "        I_combine[:,:W,:] = I1[:,:,:3]\n",
        "        I_combine[:,W:,:] = I2[:,:,:3]\n",
        "    else:\n",
        "        I2 = np.asarray(I2.resize((W,H)).convert('L'))\n",
        "        I_combine = np.zeros((H,W*2))\n",
        "        I_combine[:,:W] = I1[:,:]\n",
        "        I_combine[:,W:] = I2[:,:]\n",
        "    I_combine = PIL.Image.fromarray(np.uint8(I_combine))\n",
        "\n",
        "    W_base = 600\n",
        "    if resize:\n",
        "      ratio = W_base / (W*2)\n",
        "      H_new = int(H * ratio)\n",
        "      I_combine = I_combine.resize((W_base, H_new), PIL.Image.LANCZOS)\n",
        "\n",
        "    return I_combine\n",
        "\n",
        "filenames = os.listdir(os.path.join(input_path))\n",
        "filenames.sort()\n",
        "\n",
        "for filename in filenames:\n",
        "    print(filename)\n",
        "    image_original = PIL.Image.open(os.path.join(input_path, filename))\n",
        "    image_restore = PIL.Image.open(os.path.join(output_path, 'final_output', filename))\n",
        "\n",
        "    display(make_grid(image_original, image_restore))\n",
        "    print(\"\")\n",
        "    display(image_restore)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlyhhvUd_oUt"
      },
      "source": [
        "Existe duas formas de salvar as imagens processadas, a primeira é clicando sobre ela com o botão direito do mouse e indo até a opção \"Salvar imagem como...\", e a segunda opção é rodando o código abaixo, desta forma será gerado um arquivo zip com todas as imagens processadas.\n",
        "\n",
        "Obs: Caso rode o código abaixo e o download não inicie automaticamente, verifique as autorizações de download do seu navegador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTMJJWHNAATB"
      },
      "source": [
        "output_folder = os.path.join(upload_output_path, \"final_output\")\n",
        "print(output_folder)\n",
        "os.system(f\"zip -r -j download.zip {output_folder}/*\")\n",
        "files.download(\"download.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dTS0GOQ4yXf"
      },
      "source": [
        "#◢ Restaurar Foto Antiga (Danificada)\n",
        "Nesta seção você consegue, melhorar um pouco da qualidade da sua foto antiga, e remover danificações do tempo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e8VhnVp5rbs"
      },
      "source": [
        "No código abaixo, realizamos a restauração da imagem danificada e geramos um antes e depois para comparação do processamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkC1AKzdoygm"
      },
      "source": [
        "!rm -rf /content/imagens/output_img/\n",
        "\n",
        "%cd /content/photo_restoration/\n",
        "\n",
        "\n",
        "!python run.py --input_folder /content/imagens/input_img/ --output_folder /content/imagens/output_img/ --GPU 0 --with_scratch\n",
        "\n",
        "\n",
        "\n",
        "def imshow(a, format='png', jpeg_fallback=True):\n",
        "    a = np.asarray(a, dtype=np.uint8)\n",
        "    data = io.BytesIO()\n",
        "    PIL.Image.fromarray(a).save(data, format)\n",
        "    im_data = data.getvalue()\n",
        "    try:\n",
        "      disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "    except IOError:\n",
        "      if jpeg_fallback and format != 'jpeg':\n",
        "        print(('Warning: image was too large to display in format \"{}\"; '\n",
        "              'trying jpeg instead.').format(format))\n",
        "        return imshow(a, format='jpeg')\n",
        "      else:\n",
        "        raise\n",
        "    return disp\n",
        "\n",
        "def make_grid(I1, I2, resize=True):\n",
        "    I1 = np.asarray(I1)\n",
        "    H, W = I1.shape[0], I1.shape[1]\n",
        "    \n",
        "    if I1.ndim >= 3:\n",
        "        I2 = np.asarray(I2.resize((W,H)))\n",
        "        I_combine = np.zeros((H,W*2,3))\n",
        "        I_combine[:,:W,:] = I1[:,:,:3]\n",
        "        I_combine[:,W:,:] = I2[:,:,:3]\n",
        "    else:\n",
        "        I2 = np.asarray(I2.resize((W,H)).convert('L'))\n",
        "        I_combine = np.zeros((H,W*2))\n",
        "        I_combine[:,:W] = I1[:,:]\n",
        "        I_combine[:,W:] = I2[:,:]\n",
        "    I_combine = PIL.Image.fromarray(np.uint8(I_combine))\n",
        "\n",
        "    W_base = 600\n",
        "    if resize:\n",
        "      ratio = W_base / (W*2)\n",
        "      H_new = int(H * ratio)\n",
        "      I_combine = I_combine.resize((W_base, H_new), PIL.Image.LANCZOS)\n",
        "\n",
        "    return I_combine\n",
        "\n",
        "filenames = os.listdir(os.path.join(input_path))\n",
        "filenames.sort()\n",
        "\n",
        "for filename in filenames:\n",
        "    print(filename)\n",
        "    image_original = PIL.Image.open(os.path.join(input_path, filename))\n",
        "    image_restore = PIL.Image.open(os.path.join(output_path, 'final_output', filename))\n",
        "\n",
        "    display(make_grid(image_original, image_restore))\n",
        "    print(\"\")\n",
        "    display(image_restore)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-btg5TcAwoQ"
      },
      "source": [
        "Existe duas formas de salvar as imagens processadas, a primeira é clicando sobre ela com o botão direito do mouse e indo até a opção \"Salvar imagem como...\", e a segunda opção é rodando o código abaixo, desta forma será gerado um arquivo zip com todas as imagens processadas.\n",
        "\n",
        "Obs: Caso rode o código abaixo e o download não inicie automaticamente, verifique as autorizações de download do seu navegador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zEn377c7gEI"
      },
      "source": [
        "output_folder = os.path.join(upload_output_path, \"final_output\")\n",
        "print(output_folder)\n",
        "os.system(f\"zip -r -j download.zip {output_folder}/*\")\n",
        "files.download(\"download.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btwfOUR_Cd50"
      },
      "source": [
        "#◢ Colorir foto preto e branco\n",
        "Nesta seção você consegue, colorir uma foto preto e branco."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_8P8g_JCoQF"
      },
      "source": [
        "No código abaixo, transforma uma imagem de preto e branco para colorido.\n",
        "\n",
        "Obs: no cando direito do bloco de código abaixo, tem um seletor numerico que permite você selecionar a intensidade da coloração. Vale lembrar que cada imagem pode precisar de uma intensidade diferente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mpBIsbhs5ne"
      },
      "source": [
        "%cd /content/DeOldify/\n",
        "\n",
        "!rm -rf /content/DeOldify/result_images\n",
        "!mkdir /content/DeOldify/result_images\n",
        "\n",
        "source_url = '/content/imagens/input_img/'+ filename\n",
        "intensidade = 40  #@param {type: \"slider\", min: 7, max: 40}\n",
        "\n",
        "image_path = colorizer.plot_transformed_image(path=source_url, render_factor=intensidade, compare=True, watermarked=False)\n",
        "show_image_in_notebook(image_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCjyruEpK5ev"
      },
      "source": [
        "**Quer saber qual é a melhor intensidade para a sua foto?**\n",
        "\n",
        "Rode o código abaixo, e após descobrir, altere a intensidade no código acima e rode novamente.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCwwJmwQLQAi"
      },
      "source": [
        "for i in range(10,40,2):\n",
        "    colorizer.plot_transformed_image(path=source_url, render_factor=i, display_render_factor=True, figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3xoF-F4JDka"
      },
      "source": [
        "Existe duas formas de salvar as imagens processadas, a primeira é clicando sobre ela com o botão direito do mouse e indo até a opção \"Salvar imagem como...\", e a segunda opção é rodando o código abaixo, desta forma será gerado um arquivo zip com todas as imagens processadas.\n",
        "\n",
        "Obs: Caso rode o código abaixo e o download não inicie automaticamente, verifique as autorizações de download do seu navegador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32b84PRVJLUg"
      },
      "source": [
        "output_folder = os.path.join('/content/DeOldify/result_images')\n",
        "print(output_folder)\n",
        "os.system(f\"zip -r -j download.zip {output_folder}/*\")\n",
        "files.download(\"download.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGHc3tkNL4oU"
      },
      "source": [
        "#◢ Restaurar e Colorir\n",
        "Nesta seção você consegue, restaurar uma foto danificada e colorir ao mesmo tempo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQVmFoGWgCfC"
      },
      "source": [
        "No código abaixo, você consegue restaurar e colorir a sua imagem. Vale ressaltar que a coloração varia de acordo com a intensidade escolhida no seletor a direita do bloco de código abaixo. Caso a intensidade que você tenha escolhida não retorne a coloração esperada, você poderá usar o proximo bloco de código para ver a imagem com todas as intensidades possiveis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD8k0NyodO8G"
      },
      "source": [
        "!rm -rf /content/imagens/output_img/\n",
        "\n",
        "%cd /content/photo_restoration/\n",
        "\n",
        "!python run.py --input_folder /content/imagens/input_img/ --output_folder /content/imagens/output_img/ --GPU 0 --with_scratch\n",
        "\n",
        "filenames_upload = os.listdir(os.path.join(upload_path))\n",
        "filenames_upload.sort()\n",
        "\n",
        "filenames_upload_output = os.listdir(os.path.join(upload_output_path, \"final_output\"))\n",
        "filenames_upload_output.sort()\n",
        "\n",
        "for filename, filename_output in zip(filenames_upload, filenames_upload_output):\n",
        "    image_original = PIL.Image.open(os.path.join(upload_path, filename))\n",
        "    image_restore = PIL.Image.open(os.path.join(upload_output_path, \"final_output\", filename_output))\n",
        "\n",
        "%cd /content/DeOldify/\n",
        "\n",
        "!rm -rf /content/DeOldify/result_images\n",
        "!mkdir /content/DeOldify/result_images\n",
        "\n",
        "source_url = '/content/imagens/output_img/final_output/'+ filename\n",
        "intensidade = 33  #@param {type: \"slider\", min: 7, max: 40}\n",
        "\n",
        "\n",
        "image_path = colorizer.plot_transformed_image(path=source_url, render_factor=intensidade, compare=True, watermarked=False)\n",
        "show_image_in_notebook(image_path)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUrbDYvoeI1N"
      },
      "source": [
        "**Quer saber qual é a melhor intensidade para a sua foto?**\n",
        "\n",
        "Rode o código abaixo, e após descobrir, altere a intensidade no código acima e rode novamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDmPjUAReMM2"
      },
      "source": [
        "for i in range(10,40,2):\n",
        "    colorizer.plot_transformed_image(path=source_url, render_factor=i, display_render_factor=True, figsize=(8,8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgCdh-tQeQdl"
      },
      "source": [
        "Existe duas formas de salvar as imagens processadas, a primeira é clicando sobre ela com o botão direito do mouse e indo até a opção \"Salvar imagem como...\", e a segunda opção é rodando o código abaixo, desta forma será gerado um arquivo zip com todas as imagens processadas.\n",
        "\n",
        "Obs: Caso rode o código abaixo e o download não inicie automaticamente, verifique as autorizações de download do seu navegador."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwnFXkaUeUqX"
      },
      "source": [
        "output_folder = os.path.join('/content/DeOldify/result_images')\n",
        "print(output_folder)\n",
        "os.system(f\"zip -r -j download.zip {output_folder}/*\")\n",
        "files.download(\"download.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}